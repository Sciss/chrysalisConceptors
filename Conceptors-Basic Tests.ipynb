{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#matlab numpy conversion http://mathesaurus.sourceforge.net/matlab-numpy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nrmse(output,target):\n",
    "    combinedVar = 0.5 * (np.var(target, ddof=1) + np.var(output, ddof=1))\n",
    "    errorSignal = output - target\n",
    "    return np.sqrt(np.mean(errorSignal ** 2) / combinedVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateInternalWeights(nInternalUnits, connectivity):\n",
    "    success = False\n",
    "    internalWeights = 0\n",
    "    while success == False:\n",
    "        try:\n",
    "            internalWeights = np.random.randn(nInternalUnits,nInternalUnits) * (np.random.random((nInternalUnits,nInternalUnits)) < connectivity)\n",
    "            specRad = abs(np.linalg.eig(internalWeights)[0][0])\n",
    "            if (specRad > 0):\n",
    "                internalWeights = internalWeights / specRad\n",
    "                success = True\n",
    "        except e:\n",
    "            print(e)\n",
    "    return internalWeights\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 1000/15\n",
    "freq = 20\n",
    "waveLength = 1 / freq\n",
    "waveLengthSamples = waveLength * sr\n",
    "print(\"Wavelen: \", waveLength, \" secs , \" ,waveLengthSamples, \", samples, \", sr , \"sr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(20,4)\n",
    "# pSaw = lambda n: (round(n % waveLengthSamples) / waveLengthSamples * 2) - 1.0\n",
    "# plot([pSaw(x) for x in arange(300)])\n",
    "# pPulse = lambda n: (((n % waveLengthSamples) < (waveLengthSamples * 0.5)) * 2) - 1.0\n",
    "# plot([pPulse(x) for x in arange(300)])\n",
    "# pSine2 = lambda n: (sin(n) * sin((n+pi/4)/6))\n",
    "# plot([pSine2(x) for x in arange(100)])\n",
    "# pSine3 = lambda n: (sin(n) * sin((n/4)/6)/6)\n",
    "# plot([pSine3(x) for x in arange(100)])\n",
    "\n",
    "# pJ1 = lambda n: 1 * sin(2 * pi * n / 3.1504531)\n",
    "# plot([pJ1(x) for x in arange(100)])\n",
    "pJ1b = lambda n: 1 * sin(n/2) ** 2\n",
    "plot([pJ1b(x) for x in arange(100)])\n",
    "\n",
    "period2 = 2\n",
    "rawp = np.random.randn(period2)\n",
    "# rawp = np.array([1.1929,2.6856]);\n",
    "maxVal = np.max(rawp)\n",
    "minVal = np.min(rawp)\n",
    "print(rawp)\n",
    "rp = 0.5 * (2 * (rawp - minVal) / (maxVal - minVal) - 1);\n",
    "pJ2 = lambda n: rp[mod(n, period2 )]\n",
    "plot([pJ2(x) for x in arange(100)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def makeNetwork(p):\n",
    "    figsize(20,2)\n",
    "#    signalPlotLength = 15\n",
    "   # pattern readout learning\n",
    "    patterns = np.array([1,2])\n",
    "    \n",
    "    Netconnectivity = 1\n",
    "    if p['N'] > 20:\n",
    "        Netconnectivity = 10.0/p['N'];\n",
    "    WstarRaw = generateInternalWeights(p['N'], Netconnectivity)\n",
    "    WinRaw = np.random.randn(p['N'], 1)\n",
    "    WbiasRaw = np.random.randn(p['N'], 1)\n",
    "\n",
    "    #Scale raw weights     \n",
    "    Wstar = p['NetSR'] * WstarRaw;\n",
    "    Win = p['NetinpScaling'] * WinRaw;\n",
    "    Wbias = p['BiasScaling'] * WbiasRaw;  \n",
    "    I = np.eye(p['N'])\n",
    "    xCollector = np.zeros((p['N'], p['learnLengthWout']))\n",
    "    pCollector = np.zeros((1, p['learnLengthWout']))\n",
    "    x = np.zeros((p['N'],1))\n",
    "    \n",
    "    \n",
    "    for n in arange(p['washoutLength'] + p['learnLength']):\n",
    "        u = np.random.randn() * 1.5\n",
    "        x = np.tanh((Wstar * x) + (Win * u + Wbias))\n",
    "        if n >= p['washoutLength']:\n",
    "            xCollector[:, n - p['washoutLength']] = x[:,0]\n",
    "            pCollector[0, n - p['washoutLength']] = u\n",
    "                       \n",
    "#     print(\"Mean/Max/Min Activations, random network driven by noise\")\n",
    "#     plot(np.mean(xCollector.T, axis=1))\n",
    "#     plot(np.max(xCollector.T, axis=1))\n",
    "#     plot(np.min(xCollector.T, axis=1))\n",
    "    \n",
    "    Wout = linalg.inv(xCollector.dot(xCollector.conj().T) +  \n",
    "                  (p['TychonovAlphaReadout'] * np.eye(p['N']))).dot(xCollector).dot(pCollector.conj().transpose()).conj().T\n",
    "    print(\"Initial training\")\n",
    "    print(\"NRMSE: \", nrmse(Wout.dot(xCollector), pCollector))\n",
    "    print(\"absWeight: \", mean(abs(Wout)))\n",
    "    \n",
    "    allTrainArgs = np.zeros((p['N'], p['patts'].size * p['learnLength']))\n",
    "    allTrainOldArgs = np.zeros((p['N'], p['patts'].size * p['learnLength']))\n",
    "    allTrainTargs = np.zeros((p['N'], p['patts'].size * p['learnLength']))\n",
    "    allTrainOuts = np.zeros((1, p['patts'].size * p['learnLength']))\n",
    "    xCollectors =  np.zeros((1, p['patts'].size), dtype=np.object)\n",
    "    SRCollectors =  np.zeros((1, p['patts'].size), dtype=np.object)\n",
    "    URCollectors =  np.zeros((1, p['patts'].size), dtype=np.object)\n",
    "    patternRs =  np.zeros((1, p['patts'].size), dtype=np.object)\n",
    "    train_xPL =  np.zeros((1, p['patts'].size), dtype=np.object)\n",
    "    train_pPL =  np.zeros((1, p['patts'].size), dtype=np.object)\n",
    "    startXs =  np.zeros((p['N'], p['patts'].size), dtype=np.object)\n",
    "\n",
    "    for i_pattern in range(p['patts'].size):\n",
    "        print('Loading pattern ', i_pattern)\n",
    "        patt = p['patts'][i_pattern]\n",
    "        xCollector = zeros((p['N'], p['learnLength']))\n",
    "        xOldCollector = zeros((p['N'], p['learnLength']))\n",
    "        pCollector = zeros((1, p['learnLength']))\n",
    "        x = zeros((p['N'],1))\n",
    "        for n in range(p['washoutLength'] + p['learnLength']):\n",
    "            u = patt(n+1)\n",
    "            xOld = x\n",
    "            x = tanh((Wstar * x) + (Win * u) + Wbias)\n",
    "            if n >= p['washoutLength']:\n",
    "                xCollector[:, n - p['washoutLength']] = x[:,0]\n",
    "                xOldCollector[:, n - p['washoutLength']] = xOld[:,0]\n",
    "                pCollector[0, n - p['washoutLength']] = u\n",
    "\n",
    "        xCollectors[0,i_pattern] = xCollector\n",
    "        R = xCollector.dot(xCollector.T) / p['learnLength']\n",
    "        [Ux,sx,Vx] = svd(R)\n",
    "        SRCollectors[0,i_pattern] = diag(sx)\n",
    "        URCollectors[0,i_pattern] = Ux\n",
    "        patternRs[0,i_pattern] = R\n",
    "\n",
    "        startXs[:,i_pattern] = x[:,0]\n",
    "        \n",
    "        #needed?\n",
    "        train_xPL[0,i_pattern] = xCollector[:,:signalPlotLength]\n",
    "        train_pPL[0,i_pattern] = pCollector[0,:signalPlotLength]\n",
    "        ###\n",
    "        \n",
    "        allTrainArgs[:, i_pattern * p['learnLength']:(i_pattern+1) * p['learnLength']] = xCollector\n",
    "        allTrainOldArgs[:, i_pattern * p['learnLength']:(i_pattern+1) * p['learnLength']] = xOldCollector\n",
    "        allTrainOuts[0, i_pattern * p['learnLength']:(i_pattern+1) * p['learnLength']] = pCollector\n",
    "        allTrainTargs[:, i_pattern * p['learnLength']:(i_pattern+1) * p['learnLength']] = Win.dot(pCollector)\n",
    "         \n",
    "    Wtargets = np.arctanh(allTrainArgs) - np.tile( Wbias, (1, patterns.size * learnLength))\n",
    "\n",
    "    W = linalg.inv(allTrainOldArgs.dot(allTrainOldArgs.conj().T) +\n",
    "                      (p['TychonovAlpha'] * np.eye(p['N']))).dot(allTrainOldArgs).dot(Wtargets.conj().T).conj().T\n",
    "    print(\"W NMRSE: \", mean(nrmse(W.dot(allTrainOldArgs), Wtargets)))\n",
    "    print(\"absSize: \", mean(mean(abs(W), axis=0)))\n",
    "    \n",
    "    figure(1)\n",
    "    plot(np.mean(W.dot(allTrainOldArgs).T, axis=1))\n",
    "\n",
    "    print('Computing conceptors')\n",
    "    \n",
    "    Cs = np.zeros((4, p['patts'].size), dtype=np.object)\n",
    "    for i_pattern in range(p['patts'].size):\n",
    "        R = patternRs[0,i_pattern]\n",
    "        [U,s,V] = svd(R)\n",
    "        S = diag(s)\n",
    "        Snew = (S * linalg.inv(S + pow(alphas[i_pattern], -2) * np.eye(p['N'])))\n",
    "\n",
    "        C =  U.dot(Snew).dot(U.T);\n",
    "        Cs[0,i_pattern] = C\n",
    "        Cs[1,i_pattern] = U\n",
    "        Cs[2,i_pattern] = diag(Snew)\n",
    "        Cs[3,i_pattern] = diag(S)\n",
    "\n",
    "    x_CTestPL = np.zeros((3, p['recallTestLength'], p['patts'].size))\n",
    "    p_CTestPL = np.zeros((1, p['recallTestLength'], p['patts'].size))\n",
    "    for i_pattern in range(p['patts'].size):\n",
    "        C = Cs[0,i_pattern]\n",
    "        x = 0.5 * np.random.randn(p['N'],1)\n",
    "        for n in range(p['recallTestLength'] + p['washoutLength']):\n",
    "            x = np.tanh(W.dot(x) + Wbias)\n",
    "            x = C.dot(x)\n",
    "            if (n > p['washoutLength']):\n",
    "                x_CTestPL[:,n-p['washoutLength'],i_pattern] = x[0:3].T\n",
    "                p_CTestPL[:,n-p['washoutLength'],i_pattern] = Wout.dot(x)\n",
    "    for i_pattern in range(p['patts'].size):\n",
    "        figure(2 + i_pattern)\n",
    "        plot(p_CTestPL[:,:,i_pattern].T)\n",
    "        plot([p['patts'][i_pattern](x) for x in arange(p['recallTestLength'])])\n",
    "        \n",
    "    return locals()\n",
    "\n",
    "    \n",
    "params = {'N':100, 'NetSR':1.6, 'NetinpScaling':1.9,'BiasScaling':0.3,'TychonovAlpha':0.0001,\n",
    "         'washoutLength':200, 'learnLength':500, 'TychonovAlphaReadout':0.0001,\n",
    "         'learnLengthWout':500, 'recallTestLength':100,\n",
    "         'alphas':np.array([12.0,24.0]),\n",
    "          'patts':np.array([pJ1b, pJ2])\n",
    "         }\n",
    "\n",
    "net = makeNetwork(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run a network\n",
    "runLength = 300\n",
    "output = np.zeros(runLength)\n",
    "C = net['Cs'][0,0]\n",
    "x = 0.5 * np.random.randn(net['p']['N'],1)\n",
    "for n in range(runLength):\n",
    "    x = np.tanh(net['W'].dot(x) + net['Wbias'])\n",
    "    x = C.dot(x)\n",
    "    #x_CTestPL[:,n-p['washoutLength'],i_pattern] = x[0:3].T\n",
    "    output[n] = Wout.dot(x)\n",
    "    \n",
    "plot(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net['p']['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings ###\n",
    "hostport = 57120 ## where the OSC goes\n",
    "###\n",
    "hostip = \"127.0.0.1\"\n",
    "myip = \"127.0.0.1\"\n",
    "myport = 57804\n",
    "###\n",
    "\n",
    "import time\n",
    "import OSC\n",
    "\n",
    "\n",
    "# ========= send osc ============\n",
    "\n",
    "def sendOSCMessage( path, args ):\n",
    "  msg = OSC.OSCMessage()\n",
    "  msg.setAddress( path )\n",
    "  #print args\n",
    "  for a in args:\n",
    "    msg.append( a )\n",
    "  try:\n",
    "    oschost.send( msg )\n",
    "    if verbose:\n",
    "      print( \"sending message\", msg )\n",
    "  except OSC.OSCClientError:\n",
    "    if verbose:\n",
    "      print( \"error sending message\", msg )\n",
    "\n",
    "    #sendOSCMessage( \"/sensenode/imu\", mpusendData )\n",
    "\n",
    "#------------ OSC handlers --------------\n",
    "\n",
    "def handler_led( path, types, args, source ):        \n",
    "    print( \"Sensor input:\", args, len(args) )\n",
    "    #call function; args is an array with the values that are sent\n",
    "      \n",
    "####################### main ################\n",
    "\n",
    "oschost = OSC.OSCClient()\n",
    "send_address = ( hostip, hostport )\n",
    "oschost.connect( send_address )\n",
    "\n",
    "receive_address = ( myip, myport )\n",
    "osc = OSC.OSCServer( receive_address )\n",
    "\n",
    "# add handlers\n",
    "osc.addMsgHandler( \"/sensenode/address\", handler_led )  \n",
    "stopOSC = False\n",
    "def runOSCServer():\n",
    "    while True and not stopOSC:\n",
    "        osc.handle_request()\n",
    "        time.sleep(0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runOSCServer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 0 in a separate thread.oschandler\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BackgroundJob #0: runOSCServer()>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib import backgroundjobs as bg\n",
    "jobs = bg.BackgroundJobManager()\n",
    "jobs.new('runOSCServer()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oschandler\n",
      "Running jobs:\n",
      "0 : runOSCServer()\n",
      "\n",
      "oschandler\n",
      "oschandler\n",
      "oschandler\n",
      "oschandler\n",
      "oschandler\n",
      "oschandler\n"
     ]
    }
   ],
   "source": [
    "jobs.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopOSC=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile( Wbias, (1, patterns.size * learnLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = zeros((3,5), dtype=np.object)\n",
    "a[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean(mean(abs(W), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = np.random.random((3,5))\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q[:, 0] = a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[U,s,V] = np.linalg.svd(np.ones((3,3)))\n",
    "print U\n",
    "print diag(s)\n",
    "print V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
